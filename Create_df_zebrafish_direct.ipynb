{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mark\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import keras #code only works with this import!?\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "#import timm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from segmentation_models_pytorch import Unet\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import copy\n",
    "import random  # For random sampling\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "#0. Set user\n",
    "User=\"Mark\" #Set to Mark if you are Mark XD\n",
    "print(User)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Parameters Mark\n",
    "\n",
    "#1. Set parameters for data loading\n",
    "if User==\"Mark\":\n",
    "    \n",
    "    load_with_split = True #Load data with split or without split use the exel file\n",
    "    excel_path = \"Annotation_Zebrafish_full.xlsx\" #change if Load with split == True\n",
    "    #Df_Zebrafish_with_splits.xlsx\n",
    "    \n",
    "    images_folder = \"C:/Users/ma405l/Documents/Heidelberg_Schweregrad/Full_data/Raw_data_full_train\"\n",
    "    masks_folder = \"C:/Users/ma405l/Documents/Heidelberg_Schweregrad/Full_data/Masked_images\"\n",
    "    #2. Set parameters for data processing\n",
    "    target_size=(256,256)\t#Size of the images for training\n",
    "    num_classes = 4\n",
    "\n",
    "    #3. Train, Val, Test Split\n",
    "    train_size = 0.6\n",
    "    val_size = 0.2\n",
    "    test_size = 0.2\n",
    "    label_name = \"Curved\"\n",
    "\n",
    "    #4. Balance datasets\n",
    "    balance_train = True\n",
    "    balance_val = False\n",
    "    balance_test = False\n",
    "\n",
    "    Model_type = \"CNN\"\n",
    "\n",
    "    # Segmentation\n",
    "    Model_seg = True\n",
    "    num_epochs_seg = 1\n",
    "    criterion_seg = torch.nn.BCEWithLogitsLoss()\n",
    "    seg_directory = \"Models/Segmentation\"\n",
    "    seg_train = False\n",
    "\n",
    "    # HP Tuning\n",
    "    hp_tuning = True\n",
    "    hp_dense_layer = [512]\n",
    "    hp_lr = [2e-4]\n",
    "\n",
    "    #Use trained model for mask segmentation of images\n",
    "    use_seg_model = True\n",
    "    trained_seg_model = f\"{seg_directory}/Segmentation/seg_model.pth\"\n",
    "\n",
    "    #5 Transformer. Augmentation parameters\n",
    "    trans_rotation_range = 45\n",
    "    trans_width_shift_range = 0.2\n",
    "    trans_height_shift_range = 0.2\n",
    "    trans_zoom_range = 0.1\n",
    "    trans_horizontal_flip  = False\n",
    "    trans_fill_mode=\"nearest\"\n",
    "\n",
    "    #6 Transformer. Training parameters\n",
    "    trans_learning_rate = 0.00008 # Define learing rate\n",
    "    trans_num_epochs = 1 # Define the number of epochs\n",
    "\n",
    "    #7 Transformer. Save parameters\n",
    "    trans_log_directory = f\"Models/Transformer\"\n",
    "    trans_model_name = \"trans_model.pth\"\n",
    "    trans_metrics_name = \"trans_metrics.txt\"\n",
    "\n",
    "    #5 CNN. Augmentation parameters\n",
    "    cnn_rotation_range = 45\n",
    "    cnn_width_shift_range = 0.2\n",
    "    cnn_height_shift_range = 0.2\n",
    "    cnn_zoom_range = 0.1\n",
    "    cnn_horizontal_flip  = False\n",
    "    cnn_fill_mode=\"nearest\"\n",
    "\n",
    "    #6 CNN. Training parameters\n",
    "    \n",
    "    train_from_scratch = False #Train from scratch (vgg_16) or use pre-trained model (already trained)\n",
    "    \n",
    "    cnn_learning_rate = 0.001\n",
    "    cnn_loss = 'crossentropy'\n",
    "    cnn_num_epochs = 1\n",
    "    cnn_num_epochs_pre = 1\n",
    "    dense_layer = 512\n",
    "    dropout = 0.3\n",
    "\n",
    "    #7 CNN. Save parameters\n",
    "    cnn_log_directory = \"Models/CNN\"\n",
    "    cnn_model_name = \"vgg_16_model.keras\"\n",
    "    cnn_metrics_name = \"vgg_16_metrics.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Sample 2, Fish 21: Image or mask missing/multiple found.\n",
      "Skipping Sample 3, Fish 19: Image or mask missing/multiple found.\n",
      "Skipping Sample 3, Fish 29: Image or mask missing/multiple found.\n",
      "Skipping Sample 6, Fish 13: Image or mask missing/multiple found.\n",
      "Skipping Sample 6, Fish 26: Image or mask missing/multiple found.\n",
      "Skipping Sample 7, Fish 08: Image or mask missing/multiple found.\n",
      "Skipping Sample 7, Fish 09: Image or mask missing/multiple found.\n",
      "Skipping Sample 8, Fish 05: Image or mask missing/multiple found.\n",
      "Skipping Sample 11, Fish 18: Image or mask missing/multiple found.\n",
      "Skipping Sample 13, Fish 22: Image or mask missing/multiple found.\n",
      "Skipping Sample 14, Fish 10: Image or mask missing/multiple found.\n",
      "Skipping Sample 14, Fish 11: Image or mask missing/multiple found.\n",
      "Skipping Sample 18, Fish 27: Image or mask missing/multiple found.\n",
      "Skipping Sample 19, Fish 09: Image or mask missing/multiple found.\n",
      "Skipping Sample 26, Fish 20: Image or mask missing/multiple found.\n",
      "Skipping Sample 26, Fish 21: Image or mask missing/multiple found.\n",
      "Skipping Sample 26, Fish 23: Image or mask missing/multiple found.\n",
      "Skipping Sample 27, Fish 01: Image or mask missing/multiple found.\n",
      "Skipping Sample 28, Fish 22: Image or mask missing/multiple found.\n",
      "Skipping Sample 29, Fish 22: Image or mask missing/multiple found.\n",
      "Skipping Sample 30, Fish 16: Image or mask missing/multiple found.\n",
      "Skipping Sample 31, Fish 26: Image or mask missing/multiple found.\n",
      "Skipping Sample 31, Fish 27: Image or mask missing/multiple found.\n",
      "Skipping Sample 32, Fish 18: Image or mask missing/multiple found.\n",
      "Skipping Sample 32, Fish 19: Image or mask missing/multiple found.\n",
      "Skipping Sample 33, Fish 22: Image or mask missing/multiple found.\n",
      "Skipping Sample 33, Fish 27: Image or mask missing/multiple found.\n"
     ]
    }
   ],
   "source": [
    "#1) Match the images and masks to the exel data. \n",
    "# Create Df with the following columns: Image, Mask Path, Sample, Fish_Num, Edema, Curved, Masked Image\n",
    "if load_with_split==True:\n",
    "    def process_fish_data(excel_path, images_folder, masks_folder):\n",
    "        # Read the Excel file\n",
    "        df = pd.read_excel(excel_path, dtype={'Sample': str, 'Fish_Num': int, 'Edema': str, 'Curved': str})\n",
    "\n",
    "        # Convert Fish_Num to two-digit format (01, 02, ...)\n",
    "        df['Fish_Num'] = df['Fish_Num'].apply(lambda x: f\"{x:02d}\")\n",
    "\n",
    "        # Store results\n",
    "        results = []\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            sample = row['Sample']\n",
    "            fish_num = row['Fish_Num']\n",
    "            edema = row['Edema']\n",
    "            curved = row['Curved']\n",
    "\n",
    "            # Find the image\n",
    "            image_pattern = os.path.join(images_folder, f\"*pr_{sample}-{fish_num}*.jpg\")\n",
    "            image_files = glob.glob(image_pattern)\n",
    "\n",
    "            # Find the mask\n",
    "            mask_pattern = os.path.join(masks_folder, f\"*pr_{sample}-{fish_num}*_mask.jpg\")\n",
    "            mask_files = glob.glob(mask_pattern)\n",
    "\n",
    "            # Ensure exactly one match\n",
    "            if len(image_files) != 1 or len(mask_files) != 1:\n",
    "                print(f\"Skipping Sample {sample}, Fish {fish_num}: Image or mask missing/multiple found.\")\n",
    "                continue\n",
    "\n",
    "            image_path = image_files[0]\n",
    "            mask_path = mask_files[0]\n",
    "\n",
    "            # Load image and mask\n",
    "            image = cv2.imread(image_path)\n",
    "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            if image is None or mask is None:\n",
    "                print(f\"Skipping {image_path} or {mask_path}: Unable to read file.\")\n",
    "                continue\n",
    "\n",
    "            # Apply the mask: Everything outside the mask becomes black\n",
    "            masked_image = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "            # Store in results list\n",
    "            results.append([image_path, mask_path, sample, fish_num, edema, curved, masked_image])\n",
    "\n",
    "        # Convert to DataFrame\n",
    "        columns = ['Images', 'Masks', 'Sample', 'Fish_Num', 'Edema', 'Curved', 'Masked Images']\n",
    "        result_df = pd.DataFrame(results, columns=columns)\n",
    "\n",
    "        return result_df\n",
    "\n",
    "    df_result = process_fish_data(excel_path, images_folder, masks_folder)\n",
    "    #Delete Rows with NAW\n",
    "    df_result = df_result[df_result[label_name] != \"NAW\"]\n",
    "    # Convert label to integers\n",
    "    df_result[\"Curved\"] = df_result[\"Curved\"].astype(int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Excel file saved at: c:\\Users\\ma405l\\OneDrive\\Dokumente\\PhD\\Projects\\Zebra_Fish\\Df_Zebrafish_with_splits.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Drop the 'Masked Images' column\n",
    "df_cleaned = df_result.drop(columns=['Masked Images'])\n",
    "\n",
    "# Stratified split by 'Curved'\n",
    "train_c, temp_c = train_test_split(df_cleaned, test_size=0.4, stratify=df_cleaned['Curved'], random_state=42)\n",
    "val_c, test_c = train_test_split(temp_c, test_size=0.5, stratify=temp_c['Curved'], random_state=42)\n",
    "\n",
    "# Assign split labels for 'Curved'\n",
    "df_cleaned['split_by_curve'] = -1\n",
    "df_cleaned.loc[df_cleaned.index.isin(train_c.index), 'split_by_curve'] = 0\n",
    "df_cleaned.loc[df_cleaned.index.isin(val_c.index), 'split_by_curve'] = 1\n",
    "df_cleaned.loc[df_cleaned.index.isin(test_c.index), 'split_by_curve'] = 2\n",
    "\n",
    "# Stratified split by 'Edema'\n",
    "train_e, temp_e = train_test_split(df_cleaned, test_size=0.3, stratify=df_cleaned['Edema'], random_state=42)\n",
    "val_e, test_e = train_test_split(temp_e, test_size=1/3, stratify=temp_e['Edema'], random_state=42)\n",
    "\n",
    "# Assign split labels for 'Edema'\n",
    "df_cleaned['split_by_edema'] = -1\n",
    "df_cleaned.loc[df_cleaned.index.isin(train_e.index), 'split_by_edema'] = 0\n",
    "df_cleaned.loc[df_cleaned.index.isin(val_e.index), 'split_by_edema'] = 1\n",
    "df_cleaned.loc[df_cleaned.index.isin(test_e.index), 'split_by_edema'] = 2\n",
    "\n",
    "# Save the new Excel file\n",
    "#Diese zeile hier anpassen, wo soll die exel datai gepseichert werden? und welche datei name?\n",
    "output_path = os.path.join(os.getcwd(), \"Df_Zebrafish_with_splits.xlsx\")\n",
    "df_cleaned.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"New Excel file saved at: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
