{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\9andy\\miniconda3\\envs\\IBT_Hiwi_Zebrafish_new\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\9andy\\miniconda3\\envs\\IBT_Hiwi_Zebrafish_new\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] Die angegebene Prozedur wurde nicht gefunden'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Andrey\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import keras #code only works with this import!?\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "#import timm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from segmentation_models_pytorch import Unet\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import copy\n",
    "import random  # For random sampling\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "#0. Set user\n",
    "User=\"Mark\" #Set to Mark if you are Mark XD\n",
    "print(User)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Parameters Mark\n",
    "\n",
    "#1. Set parameters for data loading\n",
    "if User==\"Mark\":\n",
    "    \n",
    "    load_with_split = True #Load data with split or without split use the exel file\n",
    "    use_eye_masks = True #Use eye masks segmentation\n",
    "    excel_path = \"Annotation_Zebrafish_full.xlsx\" #change if Load with split == True\n",
    "    #Df_Zebrafish_with_splits.xlsx\n",
    "    \n",
    "    images_folder = \"C:/Users/ma405l/Documents/Heidelberg_Schweregrad/Full_data/Raw_data_full_train\"\n",
    "    masks_folder = \"C:/Users/ma405l/Documents/Heidelberg_Schweregrad/Full_data/Masked_images\"\n",
    "    eye_folder = #add the right folder here!!!\n",
    "    \n",
    "    #2. Set parameters for data processing\n",
    "    target_size=(256,256)\t#Size of the images for training\n",
    "    num_classes = 4\n",
    "\n",
    "    #3. Train, Val, Test Split\n",
    "    train_size = 0.6\n",
    "    val_size = 0.2\n",
    "    test_size = 0.2\n",
    "    label_name = \"Curved\"\n",
    "\n",
    "    #4. Balance datasets\n",
    "    balance_train = True\n",
    "    balance_val = False\n",
    "    balance_test = False\n",
    "\n",
    "    Model_type = \"CNN\"\n",
    "\n",
    "    # Segmentation\n",
    "    Model_seg = True\n",
    "    num_epochs_seg = 1\n",
    "    criterion_seg = torch.nn.BCEWithLogitsLoss()\n",
    "    seg_directory = \"Models/Segmentation\"\n",
    "    seg_train = False\n",
    "\n",
    "    # HP Tuning\n",
    "    hp_tuning = True\n",
    "    hp_dense_layer = [512]\n",
    "    hp_lr = [2e-4]\n",
    "\n",
    "    #Use trained model for mask segmentation of images\n",
    "    use_seg_model = True\n",
    "    trained_seg_model = f\"{seg_directory}/Segmentation/seg_model.pth\"\n",
    "\n",
    "    #5 Transformer. Augmentation parameters\n",
    "    trans_rotation_range = 45\n",
    "    trans_width_shift_range = 0.2\n",
    "    trans_height_shift_range = 0.2\n",
    "    trans_zoom_range = 0.1\n",
    "    trans_horizontal_flip  = False\n",
    "    trans_fill_mode=\"nearest\"\n",
    "\n",
    "    #6 Transformer. Training parameters\n",
    "    trans_learning_rate = 0.00008 # Define learing rate\n",
    "    trans_num_epochs = 1 # Define the number of epochs\n",
    "\n",
    "    #7 Transformer. Save parameters\n",
    "    trans_log_directory = f\"Models/Transformer\"\n",
    "    trans_model_name = \"trans_model.pth\"\n",
    "    trans_metrics_name = \"trans_metrics.txt\"\n",
    "\n",
    "    #5 CNN. Augmentation parameters\n",
    "    cnn_rotation_range = 45\n",
    "    cnn_width_shift_range = 0.2\n",
    "    cnn_height_shift_range = 0.2\n",
    "    cnn_zoom_range = 0.1\n",
    "    cnn_horizontal_flip  = False\n",
    "    cnn_fill_mode=\"nearest\"\n",
    "\n",
    "    #6 CNN. Training parameters\n",
    "    \n",
    "    train_from_scratch = False #Train from scratch (vgg_16) or use pre-trained model (already trained)\n",
    "    \n",
    "    cnn_learning_rate = 0.001\n",
    "    cnn_loss = 'crossentropy'\n",
    "    cnn_num_epochs = 1\n",
    "    cnn_num_epochs_pre = 1\n",
    "    dense_layer = 512\n",
    "    dropout = 0.3\n",
    "\n",
    "    #7 CNN. Save parameters\n",
    "    cnn_log_directory = \"Models/CNN\"\n",
    "    cnn_model_name = \"vgg_16_model.keras\"\n",
    "    cnn_metrics_name = \"vgg_16_metrics.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Parameters Andrey\n",
    "#0. Set user\n",
    "if User==\"Andrey\":\n",
    "    \n",
    "    load_with_split = True #Load data with split or without split use the exel file\n",
    "    use_eye_masks = True #Use eye masks for training or not\n",
    "    \n",
    "    excel_path = \"C:/Local_Docs/Uni/Hiwi_IBT/Zebra_Fish/Df_Zebrafish_with_splits_AT.xlsx\" #change if Load with split == True\n",
    "    images_folder = \"C:/Local_Docs/Uni/Hiwi_IBT/Zebra_Fish/Zebra_fish_data/Raw_data_full_train\"\n",
    "    masks_folder = \"C:/Local_Docs/Uni/Hiwi_IBT/Zebra_Fish/Zebra_fish_data/Raw_data_full_masks\"\n",
    "    eye_folder = \"C:/Local_Docs/Uni/Hiwi_IBT/Zebra_Fish/Zebra_fish_data/Raw_data_full_eyes\"\n",
    "\n",
    "    #2. Set parameters for data processing\n",
    "    target_size=(256,256)\t#Size of the images for training\n",
    "    num_classes = 4\n",
    "\n",
    "    #3. Train, Val, Test Split\n",
    "    train_size = 0.6\n",
    "    val_size = 0.2\n",
    "    test_size = 0.2\n",
    "    label_name = \"Curved\"\n",
    "\n",
    "    #4. Balance datasets\n",
    "    balance_train = True\n",
    "    balance_val = False\n",
    "    balance_test = False\n",
    "\n",
    "\n",
    "    # Segmentation\n",
    "    Model_seg = False\n",
    "    num_epochs_seg = 1\n",
    "    criterion_seg = torch.nn.BCEWithLogitsLoss()\n",
    "    seg_directory = \"C:/Local_Docs/Uni/Hiwi_IBT/Zebra_Fish/Models\"\n",
    "    seg_train = False\n",
    "\n",
    "    # HP Tuning\n",
    "    hp_tuning = True\n",
    "    hp_dense_layer = [512]\n",
    "    hp_lr = [1e-5]\n",
    "\n",
    "    #Use trained model for mask segmentation of images\n",
    "    use_seg_model = True\n",
    "    trained_seg_model = f\"{seg_directory}/segmentation_model.pth\"\n",
    "\n",
    "    #Select Model for classification\n",
    "    Model_type = \"CNN\"\n",
    "    Train_CNN = False\n",
    "    #5 Transformer. Augmentation parameters\n",
    "    trans_rotation_range = 45\n",
    "    trans_width_shift_range = 0.2\n",
    "    trans_height_shift_range = 0.2\n",
    "    trans_zoom_range = 0.1\n",
    "    trans_horizontal_flip  = False\n",
    "    trans_fill_mode=\"nearest\"\n",
    "\n",
    "    #6 Transformer. Training parameters\n",
    "    trans_learning_rate = 0.00008 # Define learing rate\n",
    "    trans_num_epochs = 1 # Define the number of epochs\n",
    "\n",
    "    #7 Transformer. Save parameters\n",
    "    trans_log_directory = f\"{seg_directory}/Transformer\"\n",
    "    trans_model_name = \"trans_model.pth\"\n",
    "    trans_metrics_name = \"trans_metrics.txt\"\n",
    "\n",
    "    #5 CNN. Augmentation parameters\n",
    "    \n",
    "    cnn_rotation_range = 45\n",
    "    cnn_width_shift_range = 0.2\n",
    "    cnn_height_shift_range = 0.2\n",
    "    cnn_zoom_range = 0.1\n",
    "    cnn_horizontal_flip  = True\n",
    "    cnn_fill_mode=\"nearest\"\n",
    "\n",
    "    #6 CNN. Training parameters\n",
    "    cnn_learning_rate = 0.001\n",
    "    cnn_loss = 'crossentropy'\n",
    "    cnn_num_epochs = 5\n",
    "    cnn_num_epochs_pre = 1\n",
    "    dense_layer = 512\n",
    "    dropout = 0.3\n",
    "\n",
    "    #7 CNN. Save parameters\n",
    "    train_from_scratch = False\n",
    "    trained_model_name = \"test_model.keras\"\n",
    "    cnn_log_directory = f\"{seg_directory}/CNN\"\n",
    "    cnn_model_name = \"test_model.keras\"\n",
    "    cnn_metrics_name = \"vgg_16_metrics.json\"\n",
    "    \n",
    "    #8 Evaluate Models\n",
    "    load_directory = f\"{seg_directory}/CNN\"\n",
    "    load_model_name = \"test_model.keras\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1) Match the images and masks to the exel data. \n",
    "# Create Df with the following columns: Image, Mask Path, Sample, Fish_Num, Edema, Curved, Masked Image\n",
    "if load_with_split==True and use_eye_masks==False:\n",
    "    def process_fish_data(excel_path, images_folder, masks_folder):\n",
    "        # Read the Excel file\n",
    "        df = pd.read_excel(excel_path, dtype={'Sample': str, 'Fish_Num': int, 'Edema': str, 'Curved': str})\n",
    "\n",
    "        # Convert Fish_Num to two-digit format (01, 02, ...)\n",
    "        df['Fish_Num'] = df['Fish_Num'].apply(lambda x: f\"{x:02d}\")\n",
    "\n",
    "        # Store results\n",
    "        results = []\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            sample = row['Sample']\n",
    "            fish_num = row['Fish_Num']\n",
    "            edema = row['Edema']\n",
    "            curved = row['Curved']\n",
    "\n",
    "            # Find the image\n",
    "            image_pattern = os.path.join(images_folder, f\"*pr_{sample}-{fish_num}*.jpg\")\n",
    "            image_files = glob.glob(image_pattern)\n",
    "\n",
    "            # Find the mask\n",
    "            mask_pattern = os.path.join(masks_folder, f\"*pr_{sample}-{fish_num}*_mask.jpg\")\n",
    "            mask_files = glob.glob(mask_pattern)\n",
    "\n",
    "            # Ensure exactly one match\n",
    "            if len(image_files) != 1 or len(mask_files) != 1:\n",
    "                print(f\"Skipping Sample {sample}, Fish {fish_num}: Image or mask missing/multiple found.\")\n",
    "                continue\n",
    "\n",
    "            image_path = image_files[0]\n",
    "            mask_path = mask_files[0]\n",
    "\n",
    "            # Load image and mask\n",
    "            image = cv2.imread(image_path)\n",
    "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            if image is None or mask is None:\n",
    "                print(f\"Skipping {image_path} or {mask_path}: Unable to read file.\")\n",
    "                continue\n",
    "\n",
    "            # Apply the mask: Everything outside the mask becomes black\n",
    "            masked_image = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "            # Store in results list\n",
    "            results.append([image_path, mask_path, sample, fish_num, edema, curved, masked_image])\n",
    "\n",
    "        # Convert to DataFrame\n",
    "        columns = ['Images', 'Masks', 'Sample', 'Fish_Num', 'Edema', 'Curved', 'Masked Images']\n",
    "        result_df = pd.DataFrame(results, columns=columns)\n",
    "\n",
    "        return result_df\n",
    "\n",
    "    df_result = process_fish_data(excel_path, images_folder, masks_folder)\n",
    "    #Delete Rows with NAW\n",
    "    df_result = df_result[df_result[label_name] != \"NAW\"]\n",
    "    # Convert label to integers\n",
    "    df_result[\"Curved\"] = df_result[\"Curved\"].astype(int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_with_split==True and use_eye_masks==True:\n",
    "    #Add eye mask to the df\n",
    "    #1) Match the images and masks to the exel data. \n",
    "    # Create Df with the following columns: Image, Mask Path, Sample, Fish_Num, Edema, Curved, Masked Image     \n",
    "\n",
    "    def process_fish_data(excel_path, images_folder, masks_folder, eye_folder):\n",
    "        # Read the Excel file\n",
    "        df = pd.read_excel(excel_path, dtype={'Sample': str, 'Fish_Num': int, 'Edema': str, 'Curved': str})\n",
    "\n",
    "        # Convert Fish_Num to two-digit format (01, 02, ...)\n",
    "        df['Fish_Num'] = df['Fish_Num'].apply(lambda x: f\"{x:02d}\")\n",
    "\n",
    "        # Store results\n",
    "        results = []\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            sample = row['Sample']\n",
    "            fish_num = row['Fish_Num']\n",
    "            edema = row['Edema']\n",
    "            curved = row['Curved']\n",
    "\n",
    "            # Find the image\n",
    "            image_pattern = os.path.join(images_folder, f\"*pr_{sample}-{fish_num}*.jpg\")\n",
    "            image_files = glob.glob(image_pattern)\n",
    "\n",
    "            # Find the mask\n",
    "            mask_pattern = os.path.join(masks_folder, f\"*pr_{sample}-{fish_num}*_Zebrafish_mask.jpg\")\n",
    "            mask_files = glob.glob(mask_pattern)\n",
    "\n",
    "            # Find the eye mask (just path, no loading)\n",
    "            eye_mask_pattern = os.path.join(eye_folder, f\"*pr_{sample}-{fish_num}*_Front_Eye_mask.jpg\")\n",
    "            eye_mask_files = glob.glob(eye_mask_pattern)\n",
    "\n",
    "            \n",
    "            # Ensure exactly one match for image and segmentation mask\n",
    "            if len(image_files) != 1 or len(mask_files) != 1:\n",
    "                print(f\"Skipping Sample {sample}, Fish {fish_num}: Image or mask missing/multiple found.\")\n",
    "                continue\n",
    "\n",
    "            image_path = image_files[0]\n",
    "            mask_path = mask_files[0]\n",
    "            eye_mask_path = eye_mask_files[0] if len(eye_mask_files) == 1 else None\n",
    "\n",
    "            # Load image and mask\n",
    "            image = cv2.imread(image_path)\n",
    "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            if image is None or mask is None:\n",
    "                print(f\"Skipping {image_path} or {mask_path}: Unable to read file.\")\n",
    "                continue\n",
    "\n",
    "            # Apply the mask\n",
    "            masked_image = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "            # Append to results\n",
    "            results.append([image_path, mask_path, eye_mask_path, sample, fish_num, edema, curved, masked_image])\n",
    "\n",
    "        # Convert to DataFrame\n",
    "        columns = ['Images', 'Masks', 'Eye_Masks', 'Sample', 'Fish_Num', 'Edema', 'Curved', 'Masked Images']\n",
    "        result_df = pd.DataFrame(results, columns=columns)\n",
    "\n",
    "        return result_df\n",
    "\n",
    "    df_result = process_fish_data(excel_path, images_folder, masks_folder, eye_folder)\n",
    "    df_result = df_result[df_result[label_name] != \"NAW\"]\n",
    "    df_result[\"Curved\"] = df_result[\"Curved\"].astype(int)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Excel file saved at: C:/Local_Docs/Uni/Hiwi_IBT/Zebra_Fish/Df_Zebrafish_with_splits_and_eyes_AT.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Drop the 'Masked Images' column\n",
    "df_cleaned = df_result.drop(columns=['Masked Images'])\n",
    "\n",
    "# Stratified split by 'Curved'\n",
    "train_c, temp_c = train_test_split(df_cleaned, test_size=0.4, stratify=df_cleaned['Curved'], random_state=42)\n",
    "val_c, test_c = train_test_split(temp_c, test_size=0.5, stratify=temp_c['Curved'], random_state=42)\n",
    "\n",
    "# Assign split labels for 'Curved'\n",
    "df_cleaned['split_by_curve'] = -1\n",
    "df_cleaned.loc[df_cleaned.index.isin(train_c.index), 'split_by_curve'] = 0\n",
    "df_cleaned.loc[df_cleaned.index.isin(val_c.index), 'split_by_curve'] = 1\n",
    "df_cleaned.loc[df_cleaned.index.isin(test_c.index), 'split_by_curve'] = 2\n",
    "\n",
    "# Stratified split by 'Edema'\n",
    "train_e, temp_e = train_test_split(df_cleaned, test_size=0.4, stratify=df_cleaned['Edema'], random_state=42)\n",
    "val_e, test_e = train_test_split(temp_e, test_size=0.5, stratify=temp_e['Edema'], random_state=42)\n",
    "\n",
    "# Assign split labels for 'Edema'\n",
    "df_cleaned['split_by_edema'] = -1\n",
    "df_cleaned.loc[df_cleaned.index.isin(train_e.index), 'split_by_edema'] = 0\n",
    "df_cleaned.loc[df_cleaned.index.isin(val_e.index), 'split_by_edema'] = 1\n",
    "df_cleaned.loc[df_cleaned.index.isin(test_e.index), 'split_by_edema'] = 2\n",
    "\n",
    "# Save the new Excel file\n",
    "#Diese zeile hier anpassen, wo soll die exel datai gepseichert werden? und welche datei name?\n",
    "output_path = os.path.join(os.getcwd(), \"\"Df_Zebrafish_with_splits_with_eyes.xlsx\"\") #\"Df_Zebrafish_with_splits3.xlsx\"\n",
    "df_cleaned.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"New Excel file saved at: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IBT_Hiwi_Zebrafish_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
